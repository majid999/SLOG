function [ closest ] = StructuredLatentSpace_Continious( xi, A , X,k, lambda, p, B )
%UNTITLED Summary of this function goes here
%   Detailed explanation goes here

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% matlab optimization settings

options = optimset('GradObj','on', 'Display','off');
options.TolFun = 1e-10;
options.TolX = 1e-10;
options.MaxIter = 1000;


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


XA = X*A;
xiA = xi*A;


minw = zeros(size(xind));
minfval = 100000;

for b=1:B,
    
    w0 = rand(size());
    [f df] = NoneLinearLatentSpace(w0, XA, xiA, p , lambda);
    [w fval] = fmincon(@(w)NoneLinearLatentSpace(w, XA, xiA, p , lambda),w0,[],[],[],[],zeros(size(w0)),ones(size(w0)),[],options);
    %[w fval]= L1GeneralProjectedSubGradient(@(w)NoneLinearLatentSpace(w, wtopics, xP, p , lambda, normp),w0,lambda,options);

    if fval< minfval,
        minfval = fval;
        minw = w;
    end

end
minfval
%minw(minw<0.001)=0;
w = minw;
fprintf('\n continues loss function p: %e \n', p);

wordnum = length(find(abs(w)))
for kk=1:wordnum,
    
    [val ind] = max(abs(w));
    word = wordsw{xind(ind)};
    fprintf('%s %e ', word,w(ind));
    w(ind)= 0;
    
end

w = minw;









end



function [f df] = NoneLinearLatentSpace(w, XA, xiA, p , lambda)

base = 0.001;
f1 =  sum(sum(repmat(w',1 , size(XA,2)).*XA .* repmat(xiA, size(XA,1),1)+base).^p);
f2 = norm(lambda .*w, 1);


f = -f1 +  f2;

df1 = p*(sum(repmat(w',1 , size(XA,2)).*XA .* repmat(xiX, size(XA,1),1)+ base).^(p-1));
df2 = sum(XA .* repmat(xiA, size(XA,1),1));
df3 = sum(df1 .* df2);
df4 = (abs(w)./w);
df4(w==0) = 0;

df = - df3+ lambda .* df4;



end


